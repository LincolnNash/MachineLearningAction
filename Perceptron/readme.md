# 引言（想说的话）<br>
   线性回归的数学表达式y = wx可以看出数据特征经过特征矩阵映射成实数y，
使用均方差作为损失函数在训练（最小化损失函数）过程中找到合适的参数
这些参数确定的这条直线（或者说超平面）使得每个点到这条直线的距离和
最小。在二维坐标系上可以说是用一条直线来拟合数据点。
<br>若我们要求将数据的特征映射成两个类别呢？（那多个类别呢？我们后面介绍）
那就不是用\"直线\"来拟合数据了而是用\"直线\"将数据划分开。可是我们
的线性函数输出的依然是实数值啊如何根据实数值来确定类别？我们可以将该值
输入一个阈值函数，若大与该阈值就输出正类否则输出负类。那么我们如何定义
损失函数呢？使用误分类的个数？不行这不是个连续函数不适合训练。有学者提出
用误分类的点到该线性函数确定的超平面的距离和作为损失函数，具体的学习策略
和算法请参考李航老师的《统计学习方法》
# 参考书籍<br>
* 《统计学习方法》-- 李航
